# api.py
from fastapi import FastAPI
from pydantic import BaseModel
from langgraph.types import Command

# ğŸ”„ Redis ëŒ€ì‹  PostgresSaver (Async ë²„ì „) ì‚¬ìš©
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

from langgraph.checkpoint.redis.aio import AsyncRedisSaver
from langgraph.checkpoint.memory import InMemorySaver
from langchain_openai import AzureChatOpenAI
import asyncio
from langgraph.prebuilt import ToolNode
from langchain_mcp_adapters.client import MultiServerMCPClient
# ğŸ”¹ Supervisor/Workers ê·¸ë˜í”„ ë¹Œë”
from llm.supervisor.supervisor_workers import build_supervisor
import os 
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="Stock AI (Supervisor/Workers) API")

# redis_cm = AsyncRedisSaver.from_conn_string("redis://127.0.0.1:6379")

# ğŸ” Postgres ì—°ê²° ì •ë³´ (dotenv ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
DB_URI = os.getenv(
    "POSTGRES_DB_URI",
    "postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable",
)

# ì „ì—­ Postgres Saver ì»¨í…ìŠ¤íŠ¸ & ì¸ìŠ¤í„´ìŠ¤ & ê·¸ë˜í”„
postgres_cm = AsyncPostgresSaver.from_conn_string(DB_URI)
checkpointer = None
supervisor_graph = None
llm = None
tools = None

# ==========================================================
# ğŸ§© ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
# ==========================================================
class ChatRequest(BaseModel):
    session_id: str
    text: str

class ResumeRequest(BaseModel):
    session_id: str
    human_feedback: str


# ==========================================
# FastAPI Startup ì´ë²¤íŠ¸
# ==========================================
@app.on_event("startup")
async def startup_event():
    """
    MCP ì„œë²„ ì´ˆê¸°í™” ë° Supervisor ê·¸ë˜í”„ ìƒì„±
    """
    global tools
    global llm
    global supervisor_graph
    global checkpointer

    print("ğŸš€ MCP ì„œë²„ ì´ˆê¸°í™” ì¤‘...")

    # ì—¬ëŸ¬ MCP ì„œë²„ ë“±ë¡
    client = MultiServerMCPClient(
        {
            "stock-server": {
                "url": "http://localhost:8005/sse",
                "transport": "sse",
                "timeout": 10.0,
                "sse_read_timeout": 300.0,
            },
            "tavily-mcp": {
                "transport": "stdio",
                "command": "npx",
                "args": ["-y", "tavily-mcp@0.1.4"],
                "env": {"TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")},
            },
        }
    )

    # âœ… ëª¨ë“  MCP ì„œë²„ì˜ íˆ´ì„ í•œ ë²ˆì— ë¡œë“œ
    tools = await client.get_tools()
    #['get_current_time', 'get_stock_news_sentiment', 'get_user_info', 'get_stock_symbol', 'get_auto_trading_balance', 'get_indicator', 'tavily-search', 'tavily-extract']
    print(f"âœ… MCP Tools ë¡œë”© ì™„ë£Œ: {[t.name for t in tools]}") 

    # âœ… ToolNodeë¡œ ë³€í™˜ (LangGraphì—ì„œ ê³µìš© í—ˆë¸Œë¡œ ì‚¬ìš©)
    # tool_hub  = ToolNode(tools)

    # âœ… LangGraph LLM / Checkpointer ì„¤ì •
    llm = AzureChatOpenAI(
        azure_deployment="gpt-4o-mini",
        azure_endpoint="https://sb-azure-openai-studio.openai.azure.com/",
        api_version="2024-10-21",
        temperature=0,
    )
    
    # âœ… PostgresSaver ì´ˆê¸°í™” (ê³µì‹ ë¬¸ì„œ ìŠ¤íƒ€ì¼)
    # from_conn_string ì€ async context manager ì´ë¯€ë¡œ __aenter__ ë¡œ ì‹¤ì œ saver ì¸ìŠ¤í„´ìŠ¤ íšë“
    global postgres_cm
    checkpointer = await postgres_cm.__aenter__()

    # âš ï¸ ì²« ì‹¤í–‰ ì‹œì—ë§Œ í…Œì´ë¸” ìƒì„±/ë§ˆì´ê·¸ë ˆì´ì…˜
    await checkpointer.setup()

    # âœ… Supervisor ê·¸ë˜í”„ ë¹Œë“œ (checkpointer = AsyncPostgresSaver)
    supervisor_graph = build_supervisor(llm=llm, tools=tools, checkpointer=checkpointer)
    print("âœ… Supervisor/Workers ê·¸ë˜í”„ ì¤€ë¹„ ì™„ë£Œ (PostgresSaver ì‚¬ìš©)")


@app.on_event("shutdown")
async def shutdown_event():
    global postgres_cm
    if postgres_cm is not None:
        await postgres_cm.__aexit__(None, None, None)
    print("ğŸ›‘ Shutdown complete â€” AsyncPostgresSaver closed.")

# ==========================================================
# ğŸ’¬ /agent_chat â€” ë©”ì¸ ì±— ì—”ë“œí¬ì¸íŠ¸
# ==========================================================
@app.post("/agent_chat")
async def agent_chat(req: ChatRequest):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ì„ Supervisor ê·¸ë˜í”„ì— ì „ë‹¬í•˜ì—¬ ì ì ˆí•œ Workerë¥¼ í˜¸ì¶œ.
    """
    assert supervisor_graph is not None, "Supervisor graph is not initialized"
    
    print(f"ğŸ“¨ ì…ë ¥: {req.text} (session={req.session_id})")

    config = {"configurable": {"thread_id": req.session_id}}
    payload = {"messages": [{"role": "user", "content": req.text}]}

    result = await supervisor_graph.ainvoke(payload, config)
    
    # Human-in-the-loop interrupt ì²˜ë¦¬
    interrupts = result.get("__interrupt__", [])
    print(f"interrupts: {interrupts}")
    if interrupts:
        msg = getattr(interrupts[0], "value", str(interrupts[0]))
        print(f"msg: {msg}")
        return {
            "session_id": req.session_id,
            "response": msg,
            "require_human": True
        }

    # 1) structured_responseê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
    structured = result.get("structured_response") if isinstance(result, dict) else None
    if structured is not None:
        return {
            "session_id": req.session_id,
            "response": structured  # UIì—ì„œ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ê±°ë‚˜ í•„ìš”í•˜ë©´ json.dumps(structured, ensure_ascii=False)
        }
        
    # âœ… ì•ˆì „í•˜ê²Œ content ì¶”ì¶œ
    response_text = (
        getattr(result, "response", None)
        or (
            result["messages"][-1].content
            if "messages" in result and result["messages"]
            else ""
        )
    )

    return {"session_id": req.session_id, "response": response_text}


# ==========================================================
# ğŸ” /resume â€” Human Feedback ë°˜ì˜ í›„ ì¬ê°œ
# ==========================================================
@app.post("/resume")
async def resume(req: ResumeRequest):
    """
    LangGraph interrupt ì´í›„ ì‚¬ëŒ í”¼ë“œë°±ì„ Supervisorë¡œ ì „ë‹¬í•˜ì—¬ ì‹¤í–‰ ì¬ê°œ.
    """
    #assert supervisor_graph is not None, "Supervisor graph is not initialized"
    
    print(f"ğŸ” human_feedback: {req.human_feedback} (session={req.session_id})")

    
    config = {"configurable": {"thread_id": req.session_id}}
    
    '''LangGraphëŠ” ë‚´ë¶€ì ìœ¼ë¡œ:
    Checkpoint(thread_id=abc123)ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    ì§ì „ ì¤‘ë‹¨ì§€ì (ToolNode ì‹¤í–‰ ì „)ì—ì„œ ìƒíƒœë¥¼ ë³µì›í•©ë‹ˆë‹¤.
    ì‚¬ëŒ í”¼ë“œë°±(human_feedback)ì„ stateì— ì£¼ì…í•©ë‹ˆë‹¤.
    ReAct ë£¨í”„ë¥¼ ë‹¤ì‹œ ì§„í–‰ì‹œí‚µë‹ˆë‹¤.
    '''
    
    # UIì—ì„œ ì˜¨ ë¬¸ìì—´("approve", "reject", "edit")ì„
    # LangChainì´ ê¸°ëŒ€í•˜ëŠ” decisions í¬ë§·ìœ¼ë¡œ ë³€í™˜
    decision_type = req.human_feedback
    decisions = [{"type": decision_type}]

    # async with AsyncRedisSaver.from_conn_string("redis://localhost:6379") as checkpointer:
    #     supervisor_graph = build_supervisor(llm=llm, tools=tools, checkpointer=checkpointer)
    #     result = await supervisor_graph.ainvoke(
    #         Command(resume={"decisions": decisions}),
    #         config=config
    #     )

    result = await supervisor_graph.ainvoke(
            Command(resume={"decisions": decisions}),
            config=config
        )
    
    interrupts = result.get("__interrupt__", [])
    print(f"[resume] interrupts: {interrupts}")

    if interrupts:
        msg = getattr(interrupts[0], "value", str(interrupts[0]))
        return {
            "session_id": req.session_id,
            "response": msg,
            "require_human": True
        }
    
    # âœ… ì•ˆì „í•˜ê²Œ content ì¶”ì¶œ
    response_text = (
        getattr(result, "response", None)
        or (
            result["messages"][-1].content
            if "messages" in result and result["messages"]
            else ""
        )
    )

    return {"session_id": req.session_id, "response": response_text}


# ==========================================================
# ğŸ§­ Health Check
# ==========================================================
@app.get("/")
def root():
    return {"message": "âœ… Stock AI (Supervisor/Workers) API is running"}
