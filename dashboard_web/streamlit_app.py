# streamlit_app.py
# AI ë‰´ìŠ¤ë¶„ì„ìš© -> ë§¤ìˆ˜ ì „ ì‹¤í–‰, ì¢…ëª© ì¶”ì²œ
import streamlit as st
import feedparser
import openai
import re
from datetime import datetime, date
from collections import Counter
from bs4 import BeautifulSoup
import requests
# âœ… OpenAI ì„¤ì •
from openai import OpenAI
# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key = "OPENAI_API_KEY")

# âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_stock_news(query, max_results=10, only_today=False):
    rss_url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(rss_url)
    news_items = []

    for entry in feed.entries:
        summary_cleaned = re.sub('<[^<]+?>', '', entry.summary)

        try:
            published_dt = datetime(*entry.published_parsed[:6])
            published_str = published_dt.strftime("%Y-%m-%d %H:%M")
        except:
            published_dt = None
            published_str = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

        news_items.append({
            "title": entry.title,
            "link": entry.link,
            "summary": summary_cleaned,
            "published": published_str,
            "published_dt": published_dt
        })

    # âœ… ì˜¤ëŠ˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
    if only_today:
        today = date.today()
        news_items = [item for item in news_items
                    if item["published_dt"] and item["published_dt"].date() == today]

    # âœ… ìµœì‹ ìˆœ ì •ë ¬
    news_items.sort(key=lambda x: x["published_dt"] or datetime.min, reverse=True)

    return news_items[:max_results]

# âœ… ê°ì„± ì¶”ì¶œ í•¨ìˆ˜
def extract_sentiment(text):
    match = re.search(r"\[ê°ì„±\]\s*(ê¸ì •|ë¶€ì •|ì¤‘ë¦½)", text)
    return match.group(1) if match else "ë¶„ë¥˜ ì‹¤íŒ¨"

# âœ… GPT ìš”ì•½ ë° ê°ì„± ë¶„ì„ í•¨ìˆ˜
def summarize_news_with_gpt(title, content):
    prompt = f"""
ë‹¤ìŒì€ ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤:

ì œëª©: {title}
ë‚´ìš©: {content}

1.ì´ ë‰´ìŠ¤ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
2.ë˜í•œ ì´ ë‰´ìŠ¤ê°€ íˆ¬ìì ì…ì¥ì—ì„œ ê¸ì •ì ì¸ì§€, ë¶€ì •ì ì¸ì§€, ì¤‘ë¦½ì ì¸ì§€ íŒë‹¨í•´ ì£¼ì„¸ìš”. (ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ)
3.ê·¸ë ‡ê²Œ íŒë‹¨í•œ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”:

[ìš”ì•½]
...

[ê°ì„±]
ê¸ì • / ë¶€ì • / ì¤‘ë¦½

[ì´ìœ ]
(ê°ì„± íŒë‹¨ ì´ìœ  ìš”ì•½)
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )
    return response.choices[0].message.content

# âœ… íˆ¬ì ì˜ê²¬ ìš”ì•½ í•¨ìˆ˜
def generate_investment_opinion(news_summaries, stock_name):
    prompt = f"""
ë‹¹ì‹ ì€ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” '{stock_name}'ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤:

{news_summaries}

ì´ ì¢…ëª©ì˜ ìµœê·¼ì˜ ë‰´ìŠ¤ íë¦„ê³¼ ê°ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ íˆ¬ììì—ê²Œ ì¡°ì–¸ì„ í•´ ì£¼ì„¸ìš”.
'ë§¤ìˆ˜ ê³ ë ¤ / ê´€ë§ / ë¦¬ìŠ¤í¬ ì£¼ì˜' ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

[íˆ¬ì ì˜ê²¬]
ë§¤ìˆ˜ ê³ ë ¤ / ê´€ë§ / ë¦¬ìŠ¤í¬ ì£¼ì˜ ì¤‘ íƒ 1

[ì´ìœ ]
(ê°„ë‹¨í•œ ì„¤ëª…)
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4
    )
    return response.choices[0].message.content

# âœ… Streamlit UI
st.title("ğŸ“ˆ ì¢…ëª© ë‰´ìŠ¤ ìš”ì•½ & ê°ì„± ë¶„ì„")
query = st.text_input("ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì)")
only_today = st.checkbox("ğŸ“… ì˜¤ëŠ˜ ë‰´ìŠ¤ë§Œ ë³´ê¸°")

if query:
    st.info(f'"{query}" ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...')
    news_list = get_stock_news(query, only_today=only_today)

    if not news_list:
        st.warning("ì˜¤ëŠ˜ ë‚ ì§œì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        sentiment_counter = Counter()
        summarized_texts = []
        results = []

        for i, news in enumerate(news_list):
            with st.spinner("ìš”ì•½ ë° ë¶„ì„ ì¤‘..."):
                result = summarize_news_with_gpt(news["title"], news["summary"])
            sentiment = extract_sentiment(result)
            sentiment_counter[sentiment] += 1
            summarized_texts.append(f"- {news['title']}: {result}")
            results.append((news, result))

        # âœ… ê°ì„± ìš”ì•½ í‘œì‹œ
        st.markdown("## ğŸ“Š ê°ì„± ë¶„ì„ ìš”ì•½")
        st.write(f"ğŸ‘ ê¸ì •: {sentiment_counter['ê¸ì •']}ê±´")
        st.write(f"ğŸ˜ ì¤‘ë¦½: {sentiment_counter['ì¤‘ë¦½']}ê±´")
        st.write(f"ğŸ‘ ë¶€ì •: {sentiment_counter['ë¶€ì •']}ê±´")
        st.markdown("---")

        # âœ… GPT íˆ¬ì ì˜ê²¬ í‘œì‹œ
        with st.spinner("GPTê°€ íˆ¬ì ì˜ê²¬ì„ ë¶„ì„ ì¤‘..."):
            opinion_result = generate_investment_opinion("\n".join(summarized_texts), query)

        st.markdown("## ğŸ§  GPT íˆ¬ì ì˜ê²¬")
        st.success(opinion_result)
        st.markdown("---")

        # âœ… ë‰´ìŠ¤ ì¶œë ¥
        for i, (news, result) in enumerate(results):
            st.subheader(f"ğŸ“° ë‰´ìŠ¤ {i+1}: {news['title']}")
            st.caption(f"ğŸ—“ ë‚ ì§œ: {news['published']}")
            st.write(f"[ì›ë¬¸ ë§í¬]({news['link']})")
            st.write(result)
            
            
# âœ… ì¢…ëª©ëª… â†’ ì¢…ëª©ì½”ë“œ ë§¤í•‘ (ë„¤ì´ë²„ ê²€ìƒ‰)
def get_stock_code(stock_name):
    url = f"https://search.naver.com/search.naver?query={stock_name}+ì£¼ê°€"
    res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(res.text, "html.parser")
    try:
        href = soup.select_one("a[href*='finance.naver.com/item/main.naver?code=']")["href"]
        code = re.search(r'code=(\d+)', href).group(1)
        return code
    except:
        return None

def get_company_info(stock_code):
    url = f"https://finance.naver.com/item/main.nhn?code={stock_code}"
    res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(res.text, "html.parser")

    try:
        # âœ… ì—…ì¢… ì •ë³´
        industry_tag = soup.select_one("div.description span.category")
        industry = industry_tag.text.strip().replace(">", "â€º") if industry_tag else "ì •ë³´ ì—†ìŒ"

        # âœ… ì¬ë¬´ ìš”ì•½ í…Œì´ë¸”
        table = soup.select_one("table.tb_type1.tb_num.tb_type1_ifrs")
        rows = table.select("tr") if table else []

        finance_data = {}
        for row in rows:
            th = row.select_one("th")
            tds = row.select("td")
            if th and tds and len(tds) > 1:
                label = th.text.strip()
                value = tds[1].text.strip().replace('\xa0', '')
                finance_data[label] = value

        return {
            "industry": industry,
            "finance": finance_data
        }

    except Exception as e:
        print(f"ì—ëŸ¬: {e}")
        return None

def get_financial_data(stock_code):
    url = f"https://finance.naver.com/item/main.nhn?code={stock_code}"
    res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(res.text, "html.parser")

    table = soup.select_one("table.tb_type1.tb_num.tb_type1_ifrs")
    rows = table.select("tr") if table else []

    annual_data = {}
    quarterly_data = {}

    for row in rows:
        th = row.select_one("th")
        tds = row.select("td")
        if th and len(tds) >= 6:
            label = th.text.strip()
            annual_data[label] = tds[0].text.strip()
            quarterly_data[label] = tds[3].text.strip()

    return annual_data, quarterly_data

def analyze_financials_with_gpt(fin_data, stock_name, period_label):
    summary = "\n".join([f"{k}: {v}" for k, v in fin_data.items()])

    prompt = f"""
ë‹¤ìŒì€ {stock_name}ì˜ {period_label} ì¬ë¬´ ì •ë³´ì…ë‹ˆë‹¤.

{summary}

ì´ ì¬ë¬´ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ììì˜ ì‹œê°ì—ì„œ ìš”ì•½ ë¶„ì„í•´ ì£¼ì„¸ìš”.
- ìˆ˜ìµì„±, ì„±ì¥ì„±, ì•ˆì •ì„± ê´€ì ì—ì„œ ê°„ë‹¨íˆ í‰ê°€
- ì „ë¬¸ìš©ì–´ëŠ” ì¤„ì´ê³  ì‰½ê²Œ ì„¤ëª…
- ê¸¸ì´ëŠ” 5~6ì¤„ ì´ë‚´
"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )
    return response.choices[0].message.content


# âœ… Streamlit UI
st.title("ğŸ“Š ì¢…ëª© ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ (ì—…ì¢…, ì¬ë¬´, GPT ë¶„ì„)")
stock_name = st.text_input("ë¶„ì„í•  ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì)")

if stock_name:
    st.info("ì¢…ëª© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    code = get_stock_code(stock_name)
    if not code:
        st.error("ì¢…ëª© ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        info = get_company_info(code)
        if not info:
            st.error("ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.success("âœ… ì¢…ëª© ë¶„ì„ ê²°ê³¼")

            st.subheader(f"ğŸ” [ìš”ì•½ ë³´ê³ ì„œ: {stock_name}]")
            # st.write(f"**ğŸ“‚ ì—…ì¢…:** {info['industry']}")
            #st.write(f"**ğŸ“Œ í…Œë§ˆ:** {info['theme']}")

            st.markdown("### ğŸ’° [ì¬ë¬´ ìš”ì•½]")
            for k, v in info["finance"].items():
                st.write(f"- {k}: {v}")

            # with st.spinner("GPTê°€ ì¬ë¬´ ë¶„ì„ ì¤‘..."):
            #     gpt_opinion = analyze_financials_with_gpt(info["finance"], stock_name)

            # st.markdown("### ğŸ§  [GPT ì¬ë¬´ ë¶„ì„]")
            # st.success(gpt_opinion)
            
    annual, quarterly = get_financial_data(code)
    
        # ì—°ê°„ ì‹¤ì 
    st.subheader("ğŸ“… ìµœê·¼ ì—°ê°„ ì‹¤ì ")
    for k, v in annual.items():
        st.write(f"- {k}: {v}")

    with st.spinner("GPTê°€ ì—°ê°„ ì‹¤ì ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        gpt_annual = analyze_financials_with_gpt(annual, stock_name, "ì—°ê°„")
    st.markdown("ğŸ§  GPT ì—°ê°„ ì‹¤ì  ë¶„ì„")
    st.success(gpt_annual)

    # ë¶„ê¸° ì‹¤ì 
    st.subheader("ğŸ“… ìµœê·¼ ë¶„ê¸° ì‹¤ì ")
    for k, v in quarterly.items():
        st.write(f"- {k}: {v}")

    with st.spinner("GPTê°€ ë¶„ê¸° ì‹¤ì ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        gpt_quarter = analyze_financials_with_gpt(quarterly, stock_name, "ë¶„ê¸°")
    st.markdown("ğŸ§  GPT ë¶„ê¸° ì‹¤ì  ë¶„ì„")
    st.success(gpt_quarter)
            
